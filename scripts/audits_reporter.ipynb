{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7f283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da88f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='error.log', level=logging.ERROR, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "port = 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3139bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lighthouse(url, result_path):\n",
    "    try:\n",
    "\n",
    "        print(f\"Running Lighthouse for {url}\")\n",
    "\n",
    "        print(f\"Saving report to {result_path}\")\n",
    "\n",
    "        # Run the Lighthouse CLI command on the HTML file\n",
    "        command = [\n",
    "            \"lighthouse\",\n",
    "            url,\n",
    "            \"--output=json\",\n",
    "            \"--output-path=\" + result_path,\n",
    "            \"--chrome-flags=--headless  --no-sandbox --disable-gpu\",\n",
    "            \"--only-categories=performance\"\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        \n",
    "        # Read the Lighthouse report\n",
    "        with open(result_path, 'r') as file:\n",
    "            report = json.load(file)\n",
    "        \n",
    "        # Extract scores\n",
    "        scores = {\n",
    "            'performance': report['categories']['performance']['score'] * 100\n",
    "        }\n",
    "        \n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{url} --- An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b6a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Lighthouse report for walmart\n",
      "Running Lighthouse for http://localhost:8080/walmart.html\n",
      "Saving report to ./../dataset/lh-original-reports/walmart.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for walmart\n",
      "Generating Lighthouse report for pinterest\n",
      "Running Lighthouse for http://localhost:8080/pinterest.html\n",
      "Saving report to ./../dataset/lh-original-reports/pinterest.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for pinterest\n",
      "Generating Lighthouse report for linkedin\n",
      "Running Lighthouse for http://localhost:8080/linkedin.html\n",
      "Saving report to ./../dataset/lh-original-reports/linkedin.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for linkedin\n",
      "Generating Lighthouse report for reddit\n",
      "Running Lighthouse for http://localhost:8080/reddit.html\n",
      "Saving report to ./../dataset/lh-original-reports/reddit.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for reddit\n",
      "Generating Lighthouse report for ebay\n",
      "Running Lighthouse for http://localhost:8080/ebay.html\n",
      "Saving report to ./../dataset/lh-original-reports/ebay.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for ebay\n",
      "Generating Lighthouse report for github\n",
      "Running Lighthouse for http://localhost:8080/github.html\n",
      "Saving report to ./../dataset/lh-original-reports/github.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for github\n",
      "Generating Lighthouse report for twitter\n",
      "Running Lighthouse for http://localhost:8080/twitter.html\n",
      "Saving report to ./../dataset/lh-original-reports/twitter.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for twitter\n",
      "Generating Lighthouse report for facebook\n",
      "Running Lighthouse for http://localhost:8080/facebook.html\n",
      "Saving report to ./../dataset/lh-original-reports/facebook.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for facebook\n",
      "Generating Lighthouse report for aliexpress\n",
      "Running Lighthouse for http://localhost:8080/aliexpress.html\n",
      "Saving report to ./../dataset/lh-original-reports/aliexpress.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for aliexpress\n",
      "Generating Lighthouse report for netflix\n",
      "Running Lighthouse for http://localhost:8080/netflix.html\n",
      "Saving report to ./../dataset/lh-original-reports/netflix.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for netflix\n",
      "Generating Lighthouse report for youtube\n",
      "Running Lighthouse for http://localhost:8080/youtube.html\n",
      "Saving report to ./../dataset/lh-original-reports/youtube.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for youtube\n",
      "Generating Lighthouse report for twitch\n",
      "Running Lighthouse for http://localhost:8080/twitch.html\n",
      "Saving report to ./../dataset/lh-original-reports/twitch.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for twitch\n",
      "Generating Lighthouse report for medium\n",
      "Running Lighthouse for http://localhost:8080/medium.html\n",
      "Saving report to ./../dataset/lh-original-reports/medium.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file:///usr/local/lib/node_modules/lighthouse/node_modules/puppeteer-core/lib/esm/puppeteer/node/ScreenRecorder.js:65\n",
      "        static {\n",
      "               ^\n",
      "\n",
      "SyntaxError: Unexpected token '{'\n",
      "    at Loader.moduleStrategy (internal/modules/esm/translators.js:145:18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate report for medium\n",
      "Generating Lighthouse report for quora\n",
      "Running Lighthouse for http://localhost:8080/quora.html\n",
      "Saving report to ./../dataset/lh-original-reports/quora.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m filename = get_html_file_name(file_path)\n\u001b[32m     43\u001b[39m result_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./../dataset/lh-original-reports/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mgenerate_lighthouse_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mgenerate_lighthouse_report\u001b[39m\u001b[34m(file_path, result_path)\u001b[39m\n\u001b[32m     27\u001b[39m     result_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./../dataset/lh-original-reports/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Run Lighthouse and get the scores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     scores = \u001b[43mrun_lighthouse\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scores:\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScores for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrun_lighthouse\u001b[39m\u001b[34m(url, result_path)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run the Lighthouse CLI command on the HTML file\u001b[39;00m\n\u001b[32m      9\u001b[39m command = [\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlighthouse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     url,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--only-categories=performance\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Read the Lighthouse report\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(result_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/subprocess.py:2051\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2050\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2051\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2052\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2053\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/subprocess.py:2009\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2007\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2008\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2009\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2011\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2012\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2014\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "path_to_dom_trees = \"./../dataset/original/\"\n",
    "\n",
    "def get_html_files(path):\n",
    "    html_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.html'):\n",
    "                html_files.append(os.path.join(root, file))\n",
    "    return html_files\n",
    "\n",
    "def get_html_file_name(file_path):\n",
    "    # Get the file name without the directory and extension\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name = os.path.splitext(file_name)[0]\n",
    "    return file_name\n",
    "\n",
    "\n",
    "all_dom_trees = get_html_files(path_to_dom_trees)\n",
    "\n",
    "def generate_lighthouse_report(file_path, result_path=None):\n",
    "    file_name = get_html_file_name(file_path)\n",
    "    print(f\"Generating Lighthouse report for {file_name}\")\n",
    "\n",
    "    url = f\"http://localhost:{port}/{file_name}.html\"\n",
    "\n",
    "    if result_path is None:\n",
    "        result_path = f\"./../dataset/lh-original-reports/{file_name}.json\"\n",
    "    try:\n",
    "        # Run Lighthouse and get the scores\n",
    "        scores = run_lighthouse(url, result_path)\n",
    "        if scores:\n",
    "            print(f\"Scores for {file_name}: {scores}\")\n",
    "        else:\n",
    "            print(f\"Failed to generate report for {file_name}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{file_name} --- An error occurred: {e}\")\n",
    "        print(f\"An error occurred while generating the report for {file_name}: {e}\")\n",
    "\n",
    "\n",
    "for file_path in all_dom_trees:\n",
    "    filename = get_html_file_name(file_path)\n",
    "\n",
    "    result_path = f\"./../dataset/lh-original-reports/{filename}.json\"\n",
    "\n",
    "    generate_lighthouse_report(file_path, result_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
